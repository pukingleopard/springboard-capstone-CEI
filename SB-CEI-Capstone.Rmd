---
title: "Springboard Capstone Project - CEI"
author: "James Hamilton"
date: "March 24, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(lubridate)
```

# The Question

What useful insights can be drawn from the clients' customer and invoice data?
    - Are some clients "over purchasing" because they don't understand the licensing scheme?
    - What market segments are the largest / smallest and which market segments are growing / shrinking?

To answer the first question the strategy will be to calculate a median purchase size that can be used to compare with specific orders and determine outliers. The sum of the orders of the outliers minus the "expected" buy represents the amount of over purchased dollars.

The second question can be answered by the sum of the orders across an industry segment displayed graphically.

# The Data
```{r load the data, echo=FALSE, message=FALSE, warning=FALSE}
accounts = read.csv("SB-CEI-Capstone-Account.csv", header = TRUE)
orders = read.csv("SB-CEI-Capstone-Order.csv", header = TRUE)
orderlines = read.csv("SB-CEI-Capstone-Order-Product-Line.csv", header=TRUE)
```

The data was provided by the client in the form of a text CSV export from their Salesforce database.

I focused primarily on the Account, Order, and Order Line tables. Some cleanup of the data was needed - a detailing of that activity is included at the end of this report.

### Account

The account data included the customer name and demographic data: location, employee counts, annual revenue and various industry classifiers. After data cleaning there were 2134 rows / observations in the "accounts" table.

*Account.Number*  - simply a unique identifier was used to join the account data to the order data
*Annual.Revenue*  - a dollar figure estimate of the customers annual revenue
*Employees*       - estimated number of employees of the customer
*Industry*        - broad categorization of the industry that the customer operates in

A correlation test indicates that the number of employees and Annual revenue are highly correlated (.93 at 99% confidence) across all customers indicating that using employee count alone as an indicator of the "size" of the customer would be accurate.   

### Order data

These tables included details about individual orders including unique identifiers, order date, amounts and quantities, discounts applied, terms, status, product identifiers, list price, etc.

*Net.Amount*      - Total dollar amount for the order
*Order.Date*      - Date the order was placed
*Payment.Method*  - Cash, check, credit, etc
*ProductAmount*   - Dollar amount charged for each product in the order
*Quantity*        - Number of licenses ordered for the product
*SalesOrder*      - Unique identifier

The account and order data was merged to produce a working data set that maps each line of the order to an account and industry.



Therefore, the following visuals are based on that conclusion and use the employee count as the primary indicator of client size.   

Finally, a working data set is generated containing only customers that have an Employee count > 0 - this yields a final account table with 1225 rows.
```{r Accounts, echo=FALSE}
accounts.w <- accounts %>% filter(!is.na(accounts$Employees) & 
    accounts$Employees > 0 & 
    !is.na(accounts$Annual.Revenue) & 
    accounts$Annual.Revenue > 0)

p1 <- ggplot(data = accounts.w, aes(x = Industry)) + 
  geom_bar() +
  theme(axis.text.x = element_text(size=10, angle=35, hjust=1)) +
  ylab("Count of customers")

p2 <- ggplot(data = accounts.w, aes(Industry, Employees)) +
  geom_boxplot() +
  coord_cartesian(ylim=c(0,1000)) +
  theme(axis.text.x = element_blank(), axis.title.x = element_blank()) +
  ylab("Employees")

grid.arrange(p2, p1)
```

Primary conclusions here are that the Machinery, Manufacturing and Construction industries represent the majority of the client base and those companies are predominately < 250 employees in size. "Other", "Retail", "Chemicals", "Engineering", and "Consulting" are also fairly large and will be studied as well.

```{r echo=FALSE}
Industries <- c("Chemicals","Construction","Consulting","Engineering","Machinery","Manufacturing","Other","Retail")

filter(accounts.w, Industry %in% Industries) %>%
  group_by(Industry) %>%
  select(Employees) %>%
  summary(.)
```

Here we see that these industries are represented by companies that are generally in the range of 0 - 140 employees. Specifically, across all industries about 75% of all clients have <= 140 employees. This does not however, describe which industries or companies are the "most valuable" in terms of dollars spent.


### Orders

data spanned two tables and included primarily dollar amounts, dates, quantities, payment methods and keys into other tables including the invoices and accounts tables. We are looking for two key pieces of information from this data:
    - The ratio of customer size to the amount of purchase made by industry. (in dollars and quantity of software licenses or seats purchased) This will be used to identify outliers.
    - The rate of change in amount of purchase made per industry
```{r Orders, echo=FALSE}
# Isolating columns needed from the three tables
orders$date.of.order <- mdy(orders$Order.Date)
working.ol <- orderlines[ , c("SalesOrder","Product","ProductFamily","ProductAmount","Quantity") ]
working.orders <- orders[ , c("Record.ID","date.of.order","Order.Type","Account.Number") ]
working.orders <- rename(working.orders, SalesOrder = Record.ID)
working.acct <- accounts[ , c("Account.Number",         "Billing.Country",
                              "Billing.State.Province", "Employees",
                              "Industry",               "Ownership")]
work.o <- left_join(working.ol, working.orders, by = "SalesOrder")
work <- left_join(work.o, working.acct, by = "Account.Number")

byindustry <- filter(work, Industry %in% Industries) %>%
  group_by(Industry) %>%
  summarise(median_e_count = median(Employees),
    tot_e = sum(Employees),
    median_quantity = median(Quantity),
    mean_quantity = mean(Quantity),
    max_quantity = max(Quantity),
    tot_quantity = sum(Quantity),
    median_dollars = median(ProductAmount),
    mean_dollars = mean(ProductAmount),
    max_dollars = max(ProductAmount),
    tot_dollars = sum(ProductAmount)
    )

# I chose the mean for the quantity b/c the median for all industries is 1.
byindustry$qtyratio <- byindustry$mean_quantity / byindustry$median_e_count
byindustry$dollaratio <- byindustry$median_dollars / byindustry$median_e_count

ggplot(data = byindustry, aes(x = Industry)) +
  geom_point(aes(y = dollaratio, size = qtyratio, color = tot_dollars)) +
  coord_flip()

byaccount <- filter(work, !is.na(Account.Number) & !is.na(Employees) & Employees > 0 & Industry %in% Industries) %>%
  group_by(., Industry, Account.Number, SalesOrder, date.of.order, Employees) %>%
  summarise(., 
    total_order_quantity = sum(Quantity),
    total_order_dollars = sum(ProductAmount)
  ) %>%
  arrange(., date.of.order)
byaccount$qty_per_emp <- byaccount$total_order_quantity / byaccount$Employees
byaccount$dol_per_emp <- byaccount$total_order_dollars / byaccount$Employees
byaccount$year.of.order <- year(byaccount$date.of.order)

ggplot(byaccount, aes(x = date.of.order)) +
  geom_point(aes(y = qty_per_emp, color = dol_per_emp)) +
  facet_wrap(~ Industry) + 
  xlab("Date")
```

It is important to note that about 1300 orders were removed from this analysis due to missing important column info - primarily Employee count.

Looking at these plots it appears that none of the Industries represented have a large group of purchases that are above the overall median of 1. This should be good news because that would suggest that the majority of clients have not overbought.

However, the display is fairly crowded and doesn't include the baseline value per industry so I'll show a plot for each. 

The next plots combine serveral bits of information. First, each point is an individual order and is plotted by order date along the x-axis and the quantity of the order normalized by employee count along the y-axis. The total size of the order in dollars governs the color of the point and the dollars spent per employee dictates the size of each point. Larger and "cooler" dots should be cause for concern if they fall above the overall median order quantity.

The dashed horizontal line represents the ratio of the mean order quantity to the median employee count. The solid horizontal line represents the overall median order quantity across all clients.

The expectation is that half of the points would fall below the dashed line and that *most* of the points would fall below the solid line - indicating that most purchases are within expectations if clients are purchasing only what they need.

The data points above the line in all the critical industries are relatively small in number indicating a relatively low risk for those clients about which we have demographic data.

It looks as though for most industries the majority of purchases would be characterized as "correct."

```{r Industry Specific, echo=FALSE, message=FALSE, warning=FALSE}
plot.Industry <- function(i) {
  ratio <- filter(byindustry, Industry == i)$qtyratio
  
  ggplot(data = subset(byaccount, Industry == i),
    aes(x = date.of.order)) +
    geom_point(aes(y = qty_per_emp, size = dol_per_emp, color = total_order_dollars)) +
    labs(size = "$ per Employee", color = "Order Total\n     ($)") +
    scale_color_gradientn(colors=rainbow(5)) +
    geom_line(aes(y = ratio, group=1), linetype="dashed", color="black") +
    geom_line(aes(y = 1, group=1), linetype="solid", color="black") +
    theme(axis.text.x = element_text(size=10, angle=35, hjust=1)) +
    scale_x_datetime(date_breaks = "1 month", limits = c(ymd("20150101"),ymd("20151231"))) +
    xlab("Order Date") +
    ylab("Order Qty per Employee") +
    guides(color = guide_colorbar(order = 1), size = guide_legend(order = 2)) +
    ggtitle(i)
}

lapply(Industries, plot.Industry)
```

### How can we quantify the risk?

Specifically, how much of a problem could there be if the accounts that may be over purchased were to normalize their purchasing? How much of a risk is represented by the accounts that were excluded from the plots due to missing demographics?

Calculating the sum of the orders that lie above the overall median Order quantity per employee for the most recent full year should give a decent idea of the overall risk.
```{r risk, message=FALSE, warning=FALSE, include=FALSE}

# how much from the restricted accounts is at risk for potential drop
dollars.at.risk <- filter(byaccount, qty_per_emp > 1, year.of.order == 2015) %>%
  ungroup() %>%
  select(total_order_dollars) %>%
  sum(.)

counted.orders <- filter(byaccount, year.of.order == 2015) %>%
  ungroup() %>%
  select(total_order_dollars) %>%
  sum(.)

# how much from the whole amount of orders is not counted in the restricted accounts
uncounted.orders <- filter(work, (is.na(Employees) | Employees == 0) & 
    year(date.of.order) == 2015) %>%
  select(ProductAmount) %>%
  sum(.)

# total orders from 2015
total.2015 <- filter(work, year(date.of.order) == 2015) %>%
  select(ProductAmount) %>%
  sum(.)

total.dar.2015 <- (dollars.at.risk/counted.orders)*total.2015

```

Assuming that the rate of "overbuy" will be the same in the whole population of accounts as it is in the accounts that we know demographics - we can approximate the risk in dollars from last year.

The rate of overbuy in the subset with demographics: `r format(dollars.at.risk / counted.orders, digits = 3)`   
Total dollars at risk from 2015: $`r format(total.dar.2015, digits=2, scientific = FALSE)`

```{r 2015 Total, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
orders.2015 <- filter(byaccount, year.of.order == 2015)
q3.2015 <- quantile(byaccount$total_order_dollars, probs = 0.75)

dollars.2015 <- orders.2015 %>% ungroup() %>% select(total_order_dollars) %>% sum(.)
q4.dollars.2015 <- filter(orders.2015, total_order_dollars > q3.2015) %>%
  ungroup() %>%
  select(total_order_dollars) %>%
  sum(.)

q4.projected.2015 <- filter(orders.2015, total_order_dollars > q3.2015) %>% count(.)
q4.projected.2015 <- q4.projected.2015 * median(byaccount$total_order_dollars)

industry.totals.2015 <- filter(byaccount, year.of.order == 2015) %>%
  group_by(., Industry) %>%
  summarise(., 
    median.order = median(total_order_dollars),
    q4 = quantile(total_order_dollars, probs = 0.75),
    q4.count = sum(total_order_dollars > q4),
    allorders = sum(total_order_dollars),
    q4.total = sum(ifelse(total_order_dollars > q4, total_order_dollars, 0)),
    q4.projected = sum(ifelse(total_order_dollars > q4, median.order, 0))
  )

industry.totals.2015$delta <- with(industry.totals.2015, q4.total - q4.projected)

```

